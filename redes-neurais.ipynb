{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8177925,"sourceType":"datasetVersion","datasetId":4841021}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nimport os\n\nimport cv2\nimport imghdr\n\n#removendo fotos com extensões não compativeis\ndata_dir = 'train'\n\nimage_exts = ['jpeg', 'jpg', 'bmp', 'png']\n\nfor image_class in os.listdir(data_dir):#percorrendo todas as pastas \n  if os.path.isdir(image_class):\n   for image in os.listdir(os.path.join(data_dir, image_class)): #percorrendo todas as fotos de todas as pastas\n     image_path = os.path.join(data_dir,image_class,image)\n    \n     try:\n       img = cv2.imread(image_path)\n       tip = imghdr.what(image_path)\n       if tip not in image_exts:\n         print(\"Imagem não está na extensao certa{}\".format(image_path))\n         os.remove(image_path)\n     except Exception as e:\n       print(\"Problema com a imagem{}\".format(image_path))    \n\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n #Load dataset\n data = tf.keras.utils.image_dataset_from_directory('train')\n data_iterator = data.as_numpy_iterator()\n batch = data_iterator.next()\n batch[0].shape\n batch[1]\n\nfig, ax = plt.subplots(ncols=5, figsize=(20,20)) #checando numero das categorias com as imagens\nfor idx, img in enumerate(batch[0][:5]):\n  ax[idx].imshow(img.astype(int))\n  ax[idx].title.set_text(batch[1][idx])\n    \n#Processando os dados\n#escalonando as imagens\n\ndata= data.map(lambda x, y: (x/255, y)) #para o valor do rgb ficar entre 0 e 1\nscaled_iterator = data.as_numpy_iterator()\nbatch= scaled_iterator.next() \nbatch[0].max()\n\n#Dividindo entre treino, validacao e teste\n\ntrain_size = int(len(data)*.7)\nval_size = int(len(data)*.2)\ntest_size = int(len(data)*.1)\n\ntrain = data.take(train_size)\nval = data.skip(train_size).take(val_size)\ntest = data.skip(train_size+val_size).take(test_size)\n \nfrom logging import logProcesses\n#Construindo a deep learning\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n\nmodel = Sequential()\n\nmodel.add(Conv2D(16,(3,3),1, activation='relu', input_shape=(256,256,3)))\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(32,(3,3),1, activation='relu'))\nmodel.add(MaxPooling2D())\n\n\nmodel.add(Conv2D(16,(3,3),1, activation='relu'))\nmodel.add(MaxPooling2D())\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256, activation='relu'))\n#model.add(Dense(1, activatio='sigmoid'))\n\nmodel.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])\nmodel.summary()\n\n#Treino\n\nlogdir= 'logs'\ntensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n\nhist = model.fit(train, epochs=20, validation_data=val, callbacks=[tensorboard_callback])   \n\nfig = plt.figure()\nplt.plot(hist.history['loss'], color='blue', label='loss')\nplt.plot(hist.history['val_loss'], color='orange', label='val_loss')\nfig.suptitle('Loss', fontsize=20)\nplot.show()\n    \n\n    ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-20T20:04:05.809571Z","iopub.execute_input":"2024-04-20T20:04:05.809940Z","iopub.status.idle":"2024-04-20T20:04:05.835929Z","shell.execute_reply.started":"2024-04-20T20:04:05.809909Z","shell.execute_reply":"2024-04-20T20:04:05.834625Z"},"trusted":true},"execution_count":null,"outputs":[]}]}