{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JamilePolycarpo/RedesNeurais-Imagem3D/blob/main/ImagemRedesNeurais.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aP_JLYYwTgnL"
      },
      "outputs": [],
      "source": [
        "#!pip install kaggle\n",
        " #caso seja necessário atualizar a biblioteca no google colab\n",
        "\n",
        "from google.colab import files\n",
        "files.upload() #enviar o arquivo kaggle.json\n",
        "\n",
        "#antes de importar o dataset nós iremos provisionar o local de armazenamento\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "#Alterar a permissão para evitar o aviso durante a partida da ferramenta Kaggle\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "#Aceitar a competição e copiar o endereço da API para o download do dataset\n",
        "!kaggle competitions download -c image-matching-challenge-2022\n",
        "#Descompactar o arquivo baixado\n",
        "!unzip \\*.zip  && rm *.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3Z5Yp0WaSzQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import imghdr\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
        "from keras.preprocessing import image\n",
        "\n",
        "#\n",
        "source_dir = \"/content/train\"\n",
        "target_dir = \"/content/test_images\"\n",
        "\n",
        "# Definindo a quantidade de fotos em cada\n",
        "train_ratio = 0.7\n",
        "val_ratio = 0.2\n",
        "test_ratio = 0.1\n",
        "\n",
        "# Criando as pastas de validacao, treino e teste\n",
        "train_dir = os.path.join(target_dir, \"treino\")\n",
        "val_dir = os.path.join(target_dir, \"validacao\")\n",
        "test_dir = os.path.join(target_dir, \"teste\")\n",
        "\n",
        "# Create the directories for train, validation, and test sets\n",
        "os.makedirs(train_dir, exist_ok=True)\n",
        "os.makedirs(val_dir, exist_ok=True)\n",
        "os.makedirs(test_dir, exist_ok=True)\n",
        "\n",
        "# Iterate over each subdirectory in the source directory\n",
        "for folder_name in os.listdir(source_dir):\n",
        "    folder_path = os.path.join(source_dir, folder_name, \"images\")\n",
        "\n",
        "    if os.path.isdir(folder_path):\n",
        "        #lista de todas as pastas\n",
        "        images = os.listdir(folder_path)\n",
        "\n",
        "        # Dividindo as imagens entre as pastas\n",
        "        num_images = len(images)\n",
        "        num_train = int(num_images * train_ratio)\n",
        "        num_val = int(num_images * val_ratio)\n",
        "        num_test = int(num_images * test_ratio)\n",
        "\n",
        "        # Criando as subpastas\n",
        "        train_class_dir = os.path.join(train_dir, folder_name)\n",
        "        val_class_dir = os.path.join(val_dir, folder_name)\n",
        "        test_class_dir = os.path.join(test_dir, folder_name)\n",
        "        os.makedirs(train_class_dir, exist_ok=True)\n",
        "        os.makedirs(val_class_dir, exist_ok=True)\n",
        "        os.makedirs(test_class_dir, exist_ok=True)\n",
        "        print(val_class_dir)\n",
        "\n",
        "\n",
        "        # Movendo as imagens para a pasta correspondente\n",
        "        for i in range(num_images):\n",
        "            image_path = os.path.join(folder_path, images[i])\n",
        "            if os.path.isfile(image_path):\n",
        "                if i < num_train:\n",
        "                    shutil.move(image_path, train_class_dir)\n",
        "                elif i < num_train + num_val:\n",
        "                    shutil.move(image_path, val_class_dir)\n",
        "                else:\n",
        "                    shutil.move(image_path, test_class_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKfL0rWkT1mU"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wvV40EORBZ4x"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import imghdr\n",
        "\n",
        "#removendo fotos com extensões não compativeis\n",
        "\n",
        "\n",
        "image_exts = ['jpeg', 'jpg', 'bmp', 'png']\n",
        "\n",
        "for image_class in os.listdir(target_dir):#percorrendo todas as pastas\n",
        "  if os.path.isdir(image_class):\n",
        "   for image in os.listdir(os.path.join(target_dir, image_class)): #percorrendo todas as fotos de todas as pastas\n",
        "     image_path = os.path.join(target_dir,image_class,image)\n",
        "\n",
        "     try:\n",
        "       img = cv2.imread(image_path)\n",
        "       tip = imghdr.what(image_path)\n",
        "       if tip not in image_exts:\n",
        "         print(\"Imagem não está na extensao certa{}\".format(image_path))\n",
        "         os.remove(image_path)\n",
        "     except Exception as e:\n",
        "       print(\"Problema com a imagem{}\".format(image_path))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "se4hf3Qo-Zgu",
        "outputId": "58715d83-73ce-4d1d-bd68-55c9496773ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UIeJHwj_KwY",
        "outputId": "e11fbf49-3052-420d-c4ad-a3db055d75ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3966 files belonging to 16 classes.\n",
            "Found 1130 files belonging to 16 classes.\n",
            "Found 582 files belonging to 16 classes.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "train_dataset = image_dataset_from_directory('/content/test_images/treino', batch_size=32)\n",
        "validation_dataset = image_dataset_from_directory('/content/test_images/validacao',batch_size=32)\n",
        "\n",
        "test_dataset = image_dataset_from_directory('/content/test_images/teste',batch_size=32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neuVDqx2CK5b"
      },
      "outputs": [],
      "source": [
        "for data_batch, labels_batch in train_dataset:\n",
        "  print(\"data\", data_batch.shape)\n",
        "  print(\"label\", labels_batch.shape)\n",
        "  print(data_batch[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8m1Ac8XfBkuF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "data = tf.keras.utils.image_dataset_from_directory('/content/test_images/treino', batch_size = 64)\n",
        "data_iterator = data.as_numpy_iterator()\n",
        "batch_train = data_iterator.next()\n",
        "batch_train[0].shape\n",
        "batch_train[1]\n",
        "\n",
        "data1 = tf.keras.utils.image_dataset_from_directory('/content/test_images/validacao')\n",
        "data_iterator1 = data1.as_numpy_iterator()\n",
        "batch_val = data_iterator1.next()\n",
        "batch_val[0].shape\n",
        "batch_val[1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pMZtz1tgsCN"
      },
      "outputs": [],
      "source": [
        "batch_val[2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZY0z7i2_Bssb"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "fig, ax = plt.subplots(ncols=5, figsize=(20,20)) #checando numero das categorias com as imagens\n",
        "for idx, img in enumerate(batch_train[0][:5]):\n",
        "  ax[idx].imshow(img.astype(int))\n",
        "  ax[idx].title.set_text(batch_train[1][idx])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jn6eSJmyehiQ"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(ncols=5, figsize=(20,20))\n",
        "for idx, img in enumerate(batch_val[0][:5]):\n",
        "  ax[idx].imshow(img.astype(int))\n",
        "  ax[idx].title.set_text(batch_val[1][idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vN9xvh_-EiKS"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(Rescaling(scale=1.0/255))\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(256, kernel_size=(3, 3), activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(16, activation=\"softmax\"))\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kcgJ_X1G7qh4"
      },
      "outputs": [],
      "source": [
        "#Treino\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "\n",
        "hist = model.fit(train_dataset, epochs=20, batch_size = 32,validation_data=validation_dataset)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkqC-dGaX8E8"
      },
      "outputs": [],
      "source": [
        "val\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mue04os99_02"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "accuracy = hist.history['accuracy']\n",
        "val_accuracy = hist.history['val_accuracy']\n",
        "loss = hist.history[\"loss\"]\n",
        "val_loss = hist.history[\"val_loss\"]\n",
        "epochs = range(1, len (accuracy) + 1)\n",
        "plt.plot(epochs, accuracy, \"p\", label=\"Treino acc\")\n",
        "plt.plot(epochs, val_accuracy, \"b\", label=\"Val acc\")\n",
        "plt.xlabel (\"Épocas\")\n",
        "plt.ylabel (\"%s\")\n",
        "plt.title(\"Acurácia de Treino e falidação\")\n",
        "plt.legend( )\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, \"r\", label=\"Treino loss\")\n",
        "plt.plot(epochs, val_loss, \"b\", label=\"Val loss\")\n",
        "plt.xlabel (\"Épocas\")\n",
        "plt.ylabel (\"%s\")\n",
        "plt.title(\"Loss de Treino e Validação\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oBvasWbjROoA"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "#teste com alguma imagem para ver se reconhece\n",
        "\n",
        "test_img = image.load_img(\"download.jpg\", target_size=(256,256))\n",
        "x = image.array_to_img(test_img)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "pred=model.predict(x)\n",
        "label = np.argmax(prediction[0])\n",
        "\n",
        "print(label)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPyvayfsqg1PKkM2EszY8yC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}